{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608fa9b2",
   "metadata": {},
   "source": [
    "Python code for merging the three datasets of WalMart-Features, Stores and Train CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2ddada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  Dept       Date  Weekly_Sales  IsHoliday_x  Temperature  Fuel_Price  \\\n",
      "0      1     1 2010-02-05      24924.50        False        42.31       2.572   \n",
      "1      1     1 2010-02-12      46039.49         True        38.51       2.548   \n",
      "2      1     1 2010-02-19      41595.55        False        39.93       2.514   \n",
      "3      1     1 2010-02-26      19403.54        False        46.63       2.561   \n",
      "4      1     1 2010-03-05      21827.90        False        46.50       2.625   \n",
      "\n",
      "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN  211.096358   \n",
      "1        NaN        NaN        NaN        NaN        NaN  211.242170   \n",
      "2        NaN        NaN        NaN        NaN        NaN  211.289143   \n",
      "3        NaN        NaN        NaN        NaN        NaN  211.319643   \n",
      "4        NaN        NaN        NaN        NaN        NaN  211.350143   \n",
      "\n",
      "   Unemployment  IsHoliday_y Type    Size  \n",
      "0         8.106        False    A  151315  \n",
      "1         8.106         True    A  151315  \n",
      "2         8.106        False    A  151315  \n",
      "3         8.106        False    A  151315  \n",
      "4         8.106        False    A  151315  \n",
      "(421570, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(r\"Walmart\\train.csv\")\n",
    "features = pd.read_csv(r\"Walmart\\features.csv\")\n",
    "stores = pd.read_csv(r\"Walmart\\stores.csv\")\n",
    "\n",
    "# Convert Date to datetime (dayfirst=True because format is dd-mm-yyyy)\n",
    "train[\"Date\"] = pd.to_datetime(train[\"Date\"], dayfirst=True)\n",
    "features[\"Date\"] = pd.to_datetime(features[\"Date\"], dayfirst=True)\n",
    "\n",
    "\n",
    "# Merge train with features (on Store + Date only)\n",
    "train_features = pd.merge(train, features, on=[\"Store\", \"Date\"], how=\"left\")\n",
    "\n",
    "# Merge with stores metadata\n",
    "master = pd.merge(train_features, stores, on=\"Store\", how=\"left\")\n",
    "\n",
    "# Sort by Store, Dept, Date\n",
    "master = master.sort_values(by=[\"Store\", \"Dept\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# Inspect\n",
    "print(master.head())\n",
    "print(master.shape)\n",
    "\n",
    "# Save for reuse\n",
    "master.to_csv(\"walmart_master.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05225fb8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1968796",
   "metadata": {},
   "source": [
    "Convert Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6702485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged dataset\n",
    "df = pd.read_csv(\"walmart_master.csv\")\n",
    "\n",
    "# Parse to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create new time-based features\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Week'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "df['Day'] = df['Date'].dt.day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b13a3e",
   "metadata": {},
   "source": [
    "Store & Department Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c77094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Stores: 45\n",
      "Unique Departments: 81\n",
      "Subset Shape: (858, 21)\n",
      "Stores in subset: [1 2]\n",
      "Departments in subset: [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Check how many unique stores and departments exist\n",
    "print(\"Unique Stores:\", df['Store'].nunique())\n",
    "print(\"Unique Departments:\", df['Dept'].nunique())\n",
    "\n",
    "\n",
    "\n",
    "# Select manageable subset\n",
    "subset = df[(df['Store'].isin([1, 2])) & (df['Dept'].isin([1, 2, 3]))]\n",
    "\n",
    "print(\"Subset Shape:\", subset.shape)\n",
    "print(\"Stores in subset:\", subset['Store'].unique())\n",
    "print(\"Departments in subset:\", subset['Dept'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e743ba0",
   "metadata": {},
   "source": [
    "Clean Missing Values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174a83ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store             0\n",
      "Dept              0\n",
      "Date              0\n",
      "Weekly_Sales      0\n",
      "IsHoliday_x       0\n",
      "Temperature       0\n",
      "Fuel_Price        0\n",
      "MarkDown1       552\n",
      "MarkDown2       606\n",
      "MarkDown3       558\n",
      "MarkDown4       552\n",
      "MarkDown5       552\n",
      "CPI               0\n",
      "Unemployment      0\n",
      "IsHoliday_y       0\n",
      "Type              0\n",
      "Size              0\n",
      "Year              0\n",
      "Month             0\n",
      "Week              0\n",
      "Day               0\n",
      "dtype: int64\n",
      "Store            0.000000\n",
      "Dept             0.000000\n",
      "Date             0.000000\n",
      "Weekly_Sales     0.000000\n",
      "IsHoliday_x      0.000000\n",
      "Temperature      0.000000\n",
      "Fuel_Price       0.000000\n",
      "MarkDown1       64.335664\n",
      "MarkDown2       70.629371\n",
      "MarkDown3       65.034965\n",
      "MarkDown4       64.335664\n",
      "MarkDown5       64.335664\n",
      "CPI              0.000000\n",
      "Unemployment     0.000000\n",
      "IsHoliday_y      0.000000\n",
      "Type             0.000000\n",
      "Size             0.000000\n",
      "Year             0.000000\n",
      "Month            0.000000\n",
      "Week             0.000000\n",
      "Day              0.000000\n",
      "dtype: float64\n",
      "Store                0\n",
      "Dept                 0\n",
      "Date                 0\n",
      "Weekly_Sales         0\n",
      "IsHoliday_x          0\n",
      "Temperature          0\n",
      "Fuel_Price           0\n",
      "MarkDown1            0\n",
      "MarkDown2            0\n",
      "MarkDown3            0\n",
      "MarkDown4            0\n",
      "MarkDown5            0\n",
      "CPI                  0\n",
      "Unemployment         0\n",
      "IsHoliday_y          0\n",
      "Type                 0\n",
      "Size                 0\n",
      "Year                 0\n",
      "Month                0\n",
      "Week                 0\n",
      "Day                  0\n",
      "MarkDown1_missing    0\n",
      "MarkDown2_missing    0\n",
      "MarkDown3_missing    0\n",
      "MarkDown4_missing    0\n",
      "MarkDown5_missing    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values count\n",
    "print(subset.isnull().sum())\n",
    "missing_percent = subset.isnull().mean() * 100\n",
    "print(missing_percent)\n",
    "# Impute missing values in MarkDown columns with 0\n",
    "markdown_cols = [\"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\"]\n",
    "\n",
    "for col in markdown_cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(df.isnull().sum())\n",
    "for col in markdown_cols:\n",
    "    df[col + \"_missing\"] = (df[col] == 0).astype(int)  # since NaNs were filled with 0\n",
    "\n",
    "\n",
    "df.to_csv(\"processed_walmart.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832e87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8ab3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainsight360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
